{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xception","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.optimizers import Adam\nimport pandas as pd\n\n# Path to dataset directories\ntrain_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Train\"\nvalidation_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Validation\"\ntest_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Test\"\n\n# Set batch size and image size\nbatch_size = 64\nimg_size = (299, 299)\n\n# Data generators with data augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and preprocess the training dataset\ntrain_data_x = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the validation dataset\nvalidation_data_x = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the test dataset\ntest_data_x = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load the pre-trained Xception model without the top layers\nbase_model = Xception(weights='imagenet', input_shape=(299, 299, 3), include_top=False)\n\n# Freeze the layers of the pre-trained model\nbase_model.trainable = False\n\n# Add a new output layer for binary classification\nx = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)  # 1 output node with sigmoid activation for binary classification\n\n# Create the fine-tuned model\nmodel = keras.models.Model(inputs=base_model.input, outputs=outputs)\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    train_data_x,\n    epochs=10,\n    validation_data=validation_data_x\n)\n\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\nmodel.save('xception.h5')\n\n# Save training history\nhistory_df = pd.DataFrame(history.history)\nhistory_df.to_csv('training_history_xception.csv', index=False)\n\n# Evaluate the model on the test set\nloss, accuracy = model.evaluate(test_data_x)\nprint(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.applications import Xception\nfrom keras.optimizers import Adam\nimport tensorflow as tf\ndef learning_curves(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    # Plot training and validation accuracy per epoch\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot training and validation loss per epoch\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.show()\n\nlearning_curves(history)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# Get true labels and predictions\ny_true = test_data_x.classes\ny_pred = (model.predict(test_data_x) > 0.5).astype('int32').flatten()\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Display confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix for Xception Model')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet V2S","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2S\nfrom tensorflow.keras.optimizers import Adam\nimport pandas as pd\n\n# Path to dataset directories\ntrain_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Train\"\nvalidation_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Validation\"\ntest_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Test\"\n\n# Set batch size and image size\nbatch_size = 64\nimg_size = (300, 300)\n\n# Data generators\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and preprocess the training dataset\ntrain_data_v2S = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the validation dataset\nvalidation_data_v2S = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the test dataset\ntest_data_v2S = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Define the model\nmodel = EfficientNetV2S(weights='imagenet', input_shape=(300, 300, 3), include_top=False)\n\n# Freeze the convolutional base\nmodel.trainable = False\n\n# Add custom classification head\nx = keras.layers.GlobalAveragePooling2D()(model.output)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\n\n# Compile the model\nmodel = keras.models.Model(inputs=model.input, outputs=outputs)\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(\n    train_data_v2S,\n    epochs=10,\n    validation_data=validation_data_v2S\n)\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\nmodel.save('v2s.h5')\n\n# Save training history\nhistory_df = pd.DataFrame(history.history)\nhistory_df.to_csv('training_history_v2s_2.csv', index=False)\n\n# Evaluate the model on the test set\nloss, accuracy = model.evaluate(test_data_v2S)\nprint(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get true labels and predictions for EfficientNetV2-S\ny_true_v2s = test_data_v2S.classes\ny_pred_v2s = (model.predict(test_data_v2S) > 0.5).astype('int32').flatten()\n\n# Compute confusion matrix for EfficientNetV2-S\ncm_v2s = confusion_matrix(y_true_v2s, y_pred_v2s)\n\n# Display confusion matrix for EfficientNetV2-S\ndisp_v2s = ConfusionMatrixDisplay(confusion_matrix=cm_v2s, display_labels=['Class 0', 'Class 1'])\ndisp_v2s.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix for EfficientNetV2-S Model')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.applications import Xception\nfrom keras.optimizers import Adam\nimport tensorflow as tf\ndef learning_curves(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    # Plot training and validation accuracy per epoch\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot training and validation loss per epoch\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.show()\n\nlearning_curves(history)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Efficientnet V2M","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetV2M\nfrom tensorflow.keras.optimizers import Adam\nimport pandas as pd\n\n# Path to dataset directories\ntrain_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Train\"\nvalidation_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Validation\"\ntest_dir = \"/kaggle/input/deepfake-and-real-images/Dataset/Test\"\n\n# Set batch size and image size\nbatch_size = 64\nimg_size = (260, 260)\n\n# Data generators with data augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Load and preprocess the training dataset\ntrain_data_v2M = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the validation dataset\nvalidation_data_v2M = validation_datagen.flow_from_directory(\n    validation_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Load and preprocess the test dataset\ntest_data_v2M = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Step 1: Load the EfficientNetV2-M model without the top classification layer\nbase_model = EfficientNetV2M(weights='imagenet', input_shape=(260, 260, 3), include_top=False)\n\n# Step 2: Freeze the convolutional base\nbase_model.trainable = False\n\n# Step 3: Add custom classification head\nx = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutputs = keras.layers.Dense(1, activation='sigmoid')(x)\n\n# Step 4: Compile the model\nmodel = keras.models.Model(inputs=base_model.input, outputs=outputs)\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Step 5: Train the model\nhistory = model.fit(\n    train_data_v2M,\n    epochs=10,\n    validation_data=validation_data_v2M\n)\n\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\nmodel.save('v2m.h5')\n\n# Save training history\nhistory_df = pd.DataFrame(history.history)\nhistory_df.to_csv('training_history_v2m_2.csv', index=False)\n\n# Evaluate the model on the test set\nloss, accuracy = model.evaluate(test_data_v2M)\nprint(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nfrom keras.applications import Xception\nfrom keras.optimizers import Adam\nimport tensorflow as tf\ndef learning_curves(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    epochs = range(1, len(acc) + 1)\n    \n    # Plot training and validation accuracy per epoch\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'b', label='Training accuracy')\n    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot training and validation loss per epoch\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.show()\n\nlearning_curves(history)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get true labels and predictions for EfficientNetV2-M\ny_true_v2m = test_data_v2M.classes\ny_pred_v2m = (model.predict(test_data_v2M) > 0.5).astype('int32').flatten()\n\n# Compute confusion matrix for EfficientNetV2-M\ncm_v2m = confusion_matrix(y_true_v2m, y_pred_v2m)\n\n# Display confusion matrix for EfficientNetV2-M\ndisp_v2m = ConfusionMatrixDisplay(confusion_matrix=cm_v2m, display_labels=['Class 0', 'Class 1'])\ndisp_v2m.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix for EfficientNetV2-M Model')\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]}]}